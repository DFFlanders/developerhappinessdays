# Catching the long tail of research data #

The premise of my proposal is that large amounts of research data, gathered by researchers in small groups, are lost when the original research has been completed and the papers have been published.  This despite there being significant investment in building up suitable repositories for collecting, preserving and publishing data.  It seems that good progress is being made to preserve and disseminate data from larger-scale projects with access to IT development capacity, but that vast amounts of painstakingly-collected data from small groups is slipping through the net.

I posit that part of the reason for this is much data is gathered by small research groups without the expertise or capacity to build IT systems to share and organize their data, and for such groups the activation energy required to use VRE-type systems is too high for the benefit to their primary research.

Thus, I would like to explore, as a "paper prototype", the presented form of a system the aims to capture, in as lightweight fashion as possible, research data generated by small research teams, initially on their own personal computers, and help to organize and annotate the data sufficiently for subsequent preservation and publication.  The prototyping stage should not assume any particular supporting technology or platform (other than using the web), but rather focus on the user interactions.  I'm particularly interested in getting ideas about user interactions that can be used to capture information about the research data without imposing barriers to the researchers' main interest.

Having noted that the interactions should not be based on existing systems, my hope is that a suitable solution can be assembled substantially from available software.

For an example of what might be required, think of a "Flickr for researchers".

# Revised proposal #

_This revised proposal has come about as a result of discussing the earlier proposal with Nick Catto, who pointed me to a commercial system at GetDropBox.com, which appears to satisfy all of the usability requirements captured in the user stories below.  As a result, the proposal has been reformulated as a development project using a system like that at GetDropBox.com as a basis for early user prototypes._

_What follows is a transcription and expansion of some notes I used for a Dev8D "mock-dragons den" pitch, revised to take account of feedback received._

  1. This proposal derives from my work in a small research group of 4 people in the Zoology department at Oxford University, and the work we have been doing with small research groups into _Drosophila_ (fruit fly) gene function.
  1. The target user base for this development is small research groups who are creating modest amounts of high-value scientific data
    * In our previous work (Defining Image Access), we have noticed a death of research data content in institutional repositories.  Why is this?  One reason seems to be that it is too hard for small research groups to organize and submit their data to institutional repositories.
    * It seems that current research support systems (VREs and friends) provide reasonable facilities for (a) administrative support and related activities that are not specific to a particular domain of research, and (b) larger research groups who have access to IT custom development capacity (e.g. projects like the Cambridge Protein Trap, and many environmental and medical research projects).
    * But many smaller projects (e.g. 2-6 people) are not being served, not having access to capacity for setting up complex systems, but which nonetheless are generating high-value (or high-cost) results, and their research data are being lost.
    * We have observed that small life-science research groups are very reluctant to invest time and effort in complex systems, sometimes even when they can see the potential value in using them.  Many VRE system developments fail at this first hurdle.
  1. To address this problem of lost research data, we propose to assemble a lightweight system that makes it really easy for researchers to to capture their data and associated annotations within their existing workflows.
  1. An example research project:  this describes a specific project, but one that we believe is illustrative of many small-scale science research projects.
    * Studying of in situ gene expression in _Drosophila_ (fruit fly) testes, as part of wider investigations into factors affecting male infertility in various organisms, including humans.
    * A _Drosophila_ in-situ gene expression image - shows anatomical regions and physiological processes where a given gene is expressed.  In order to interpret this image, the particular gene and the strain of organism must also be recorded - without this information, the image alone is meaningless.
      * _(Drosophila in situ image here)_
    * Further observations that are extremely valuable to retain for future reference include: notes of the anatomical regions where gene expression can be seen, reasons for choice of this gene for in situ imaging, associated microarray data, associated RT-PCR (Real-time Polymerase Chain Reaction) data.  Researchers typically collect all this information in spreadsheets on their desktop PCs.
      * _(in situ annotation spreadsheet example)_
    * This research project had an estimated total budget of about Â£800K (two FTE people over 3 years, plus special equipment, microarray arrays, etc.), and produced images of about 1000 different genes.
    * In the normal run of things, this valuable data may well end up on a researchers personal computer hard drive, and lost to further review and re-use by other groups.
  1. We propose a project to assemble the following, re-using existing software possible where possible, and developing new components where needed.
  1. Core deliverables.  These represent an irreducible minimum system, whose development timescale will depend crucially on the availability of existing components.  Especially, the data acquisition component would be large project to develop from scratch, but we fully expect that existing software can achieve this is a fashion minimally acceptable to researchers.
    * Tools to collect researcher data from researchers' PCs to a managed location, where it can be made safe (backed up) and shared in controlled fashion within the research group and with research collaborators.  We anticipate this will take the form of a simple web interface, and/or a "web file system", where data is copied to a designated staging area using familiar file management tools.  The system at GetDropBox.com may be used as an initial prototype to elicit user feedback.  I understand a similar system is being developed at Cambridge University which could be a candidate for this deliverable.
      * _(GetDropBox demo/screencast here)_
    * Tools to associate a minimum set of annotations and metadata with a collection opf data files, sufficient to meet the metadata requirements for institutional repository deposition.  Once captured, these annotations will be kept with the data, avoiding the need for re-entry.
      * _(Demo entry form here - keep it simple!)_
    * Tools to perform automated submission to an institutional repository, probably usimng the SWORD protocol.
      * _(Demo submission form here - again, keep it simple!)_
  1. Additional deliverables.  These additional developments build upon the minimum core, and the extent to which they are completed in a fixed-term project will depend on availability of off-the-shelf tools for the core deliverables.
    * Usability improvements: work with researchers to make the system easier for them to adopt and use within their existing work practices. (Any improvements to their working practices should come about as a result of, not a prerequisite of, their using the system.)
    * Metadata extraction tools: customizable tools to extract researcher annotations from spreadsheets, and maybe other kinds of document, so that they can be exposed in ways that facilitate discovery and re-use of the research data.  These tools will work with and enhance the annotation tools provided as a core deliverable.
      * _(Sample screenshot, linking spreadsheet data to images)_
    * Tools to support data cleaning (e.g. consistent use of controlled vocabularies, appropriate linkages between entities).
      * _(Sample screenshot, offer options for keyword field)_
    * Data publication tools:  allowing a researcher to publish some or all of their data as an open linked dataset on the Web.  In its simplest form, such publication could consist of web-accessible data files and some associated RDF metadata.  We have good contacts with Talis, and the Talis Platform appears to be a strong contender for achieving long-term availability of openly published datasets.
      * _(Demo submission form here - again, keep it simple!)_
    * Data access, viewing and mashup tools.  Following on from our FlyWeb work, which has developed a number of simple tools focused on articulated researcher requirements, providing some tools to make it easy to locate, review and access open published datasets.  This would probably be in the form examplars taken from requirements of researchers with whom we work.  Modular, open source code will allow other developers to adapt these exemplars to differing user requirements.
      * _(FlyWeb demo screencast, as example of mashup application)_
    * There are many other areas of functionality that could be investigated and developed: licensing, versioning, visualization tools.  None of these are explicitly intend to addressed by this proposed project, except to the extent they are needed to support user requirements arising directly from working with the core system;  i.e. enhancements we can add to make the system immediately more useful or usable to our research users.
  1. Researcher benefits
    * Immediately: safety of data - access to automatic backups
    * Immediately: facilitate sharing within the research group and with collaborators
    * Mid-term: facilitating compliance with research grants that increasingly require publication of data as well as papers reporting results
    * Long-term: enhanced academic reputation through recognition and re-use of good datasets by other researchers
    * Long-term: better public awareness of research work and benefits by allowing different views on the data to be created by public communicators
    * Long-term: enabling new lines of research that build upon earlier results and data
  1. Summary of key points
    * Supporting **small** research groups
    * Preserving and exploiting modestly-sized, high-value datasets
    * Ultra-low "activation energy" for bench researchers
    * Enabling preservation, open publication, re-use and re-mixing of research data


# Sketch of prototypical user #

_This sketch is based on real researchers with whom we have worked, is intended as an illustration rather than a constraining specification, and does not purport to present an accurate description of any real person.  Nothing here should be taken as limiting the kind of research data of supporting functions that might be provided._

Helen leads a small research group conducting research into genetic function in _Drosophila_ (fruit fly).  She is a University lecturer and is PI on a couple of BBSRC-funded research projects.  Helen uses a Macintosh desktop, and her most frequently used applications are a web browser to access bioinformatic databases, Excel to analyze data, word and Powerpoint to prepare papers and presentations.  Helen also maintains collaborations with _Drosophila_ researchers in other universities, exchanging biomaterial samples, data, images and ideas.

Liz is a post-doc working for Helen, leads much of the day-to-day research activity for the main research project running in Helen's lab, and collaborates with Helen in authoring papers.  Liz' computer is a PC, and uses the same applications as Helen. Liz also particpates in external collaborations.

Lynne is a research associate who undertakes much of the research data acquisition and annotation, and other research group activities.

The research involves a moderately complex workflow involving biological assays (microarray, PCR), statistical data analysis for sample selection, sample preparation (dissection and preparation of slides for microscopy, capture of microscopic images using a PC-connected high-quality video camera attached to a microscope.  The lab containing the microscope, camera and image-capture PC is two levels above the research group's main work area.  In the first instance, images are captured locally and annotations are captured in a notebook.  The annotations are later transferred to a spreadsheet for further analysis.

The amount of research effort that does into the observation and data capture of =each sample is very significant.  This is no high-volume automated data acquisition facility, so almost every byte is valuable.  Over the course of a three year project with three researchers (2 people FTE?), the about 6000 samples are imaged and annotated.  A back-of-envelope calculation suggests an acquisition cost of about Â£20,000/sample (assuming 200K pppa including lab and equipment costs.)

The resulting images are meaningless without associated metadata about at least the strain of organism and identification gene whose expression is images.  Significant information that would be very difficult to reconstruct post-hoc is annotation of the biological regions within which the gene is expressed.

In  summary, the picture here is of modest data volumes of fairly complex information with very high per-sample or per-image collection costs.


# High-level problem statement #

Despite investment in repositories and supporting systems, much of the data produced by small research groups is lost to further use when the original research project is completed.

By "small research group", I mean groups with maybe 2-6 people with to access to IT expertise or capacity top develop or deploy specialist systems to support their research.

# Second-level problems #

_Of course, any of these statements about "existing systems" may be refuted by existence proof_

  * Existing research environment systems are too complex or difficult to use or set up for our users.  The effort required is not, in their perception, justified by the benefits.
  * Existing data sharing systems don't provide easy access to the required capabilities (e.g. associate spreadsheet data with images)
  * Existing systems don't provide access to the structure inherent in the data (e.g. search for images of expression of a specified gene indicated by a spreadsheet column).
  * To (usefully) enable preservation and publication of data, some degree of descriptive metadata (administrative and domain-related; e.g. researcher name, sample strain).  It is assumed that most of the required metadata is available somewhere in the data.

# User stories #

The template format used here (As a ... I want ... so that ...) helps to ensure these requirements are related to **user** requirements rather than (questionable) technical requirements.

The stories here are my best estimate of requirements of users I have worked with, but they have not (yet) been fully validated with these users.  As such, I am trying to e a proxy for the researcher here, which is less-than-ideal.

## Sharing between collaborators ##

As a: small research group

We want: to be able easily to share data with local and remote collaborators without immediately making it publicly accessible

So that:
  * we can pool insights, analysis and data to improve research results
  * we can capture data on one computer and analyze them on another

## Safety of data ##

As a: small research group

We want: captured data to be safe from loss caused by system failure or unexpected events

So that:  (obvious!)

## Submission to repository ##

As a: small research group

We want: to easily submit data to an institutional repository

So that: our personal, institutional and research council investment is preserved for possible future use.

Note: simply preserving raw data is not enough; a repository will require some administrative metadata to be created, and accessibility of the preserved data will be improved if it can be keyed on relevant research parameters (gene id, etc.)

## Publication of data ##

As a: small research group

We want: to easily make our data available for public access

So that:
  * we can gain personal kudos when our work is re-used and acknowledged by other researchers (and maybe, in future, real RAE-style status enhancement).
  * to satisfy the requirements of some research funding agencies
  * our research can contribute more effectively the a general public good, through re-use and secondary research

Note: it will often be a requirement that publication of data is embargoed until papers have been published and/or local programmes of data analysis have run their course.

Note: simply preserving raw data is not enough; a repository will require some administrative metadata to be created, and accessibility of the preserved data will be improved if it can be keyed on relevant research parameters (gene id, etc.)

## Updating data ##

As a: small group researcher

I want: to be able to update (change, replace) data that I have shared with collaborators

So that: I can share early results for discussion with colleagues, and for safety, without these tentative data becoming part of the eventually preserved and/or published

## Use commonly available tools ##

As a: small group researcher

I want: to have access to the various benefits of data management without installing new software on the computer being used

So that:
  * I do not have to be bothered with installing and configuring new software
  * I can access my data from any suitably-connected computer (e.g. for discussion with colleagues at a conference)


## Selective preservation/publication ?? ##

(TBD - the general idea is to allow a researcher to select datasets or parts of datasets for open publication, rather than just publishing everything.  This would be used, e.g., for not exposing data with known errors or where privacy concerns may require restrictions on publication.)


## Recover older versions of shared data ?? ##

(TBD - the idea is that updated copies of data files will be version-managed, with the latest version normally visible, but with facilities to recover older versions.  Maybe useful for recovering from operator errors, or checking earlier results, etc.)


# References #

  * Findings of the Scoping Study Interviews and the Research Data Management Workshop (Executive summary) - http://ora.ouls.ox.ac.uk/objects/uuid%3A4e2b7e64-d941-4237-a17f-659fe8a12eb5/datastreams/ATTACHMENT01

  * Findings of the Scoping Study Interviews and the Research Data Management Workshop (Main report) - http://ora.ouls.ox.ac.uk/objects/uuid%3A4e2b7e64-d941-4237-a17f-659fe8a12eb5/datastreams/ATTACHMENT02